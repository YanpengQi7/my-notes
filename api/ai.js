// AI API æœåŠ¡
// éœ€è¦å®‰è£…: npm install openai

import { OpenAI } from 'openai';

// Vercel Serverless å‡½æ•°å¤„ç†å™¨
export default async function handler(req, res) {
  // æ·»åŠ  CORS æ”¯æŒ
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  const { query, type } = req.body;

  if (!query) {
    return res.status(400).json({ error: 'Query is required' });
  }

  try {
    const result = await generateWithOpenAI(query, type);
    res.status(200).json(result);
  } catch (error) {
    console.error('API Error:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
}

async function generateWithOpenAI(content, type) {
  try {
    // å¦‚æœæ²¡æœ‰é…ç½® API Keyï¼Œä½¿ç”¨æ™ºèƒ½å¤‡ç”¨å“åº”
    if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'your_openai_api_key_here') {
      console.log('ğŸ”„ ä½¿ç”¨æ™ºèƒ½å¤‡ç”¨ç³»ç»Ÿ - å¦‚éœ€çœŸæ­£çš„AIå“åº”ï¼Œè¯·é…ç½®æœ‰æ•ˆçš„OPENAI_API_KEY');
      return generateSmartFallback(content, type);
    }

    console.log('ğŸ¤– æ­£åœ¨è°ƒç”¨ OpenAI API...');

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });

    // æ ¹æ®ç±»å‹æ„å»ºæç¤ºè¯
    let prompt = '';
    switch (type) {
      case 'summary':
        prompt = `è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š\n\n${content}`;
        break;
      case 'keywords':
        prompt = `è¯·ä»ä»¥ä¸‹å†…å®¹ä¸­æå–5-8ä¸ªå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼š\n\n${content}`;
        break;
      case 'advice':
        prompt = `åŸºäºä»¥ä¸‹å†…å®¹ï¼Œç»™å‡º3æ¡å®ç”¨çš„å­¦ä¹ å»ºè®®ï¼š\n\n${content}`;
        break;
      case 'expand':
        prompt = `è¯·æ‰©å±•ä»¥ä¸‹å†…å®¹ï¼Œæ·»åŠ æ›´å¤šç›¸å…³ä¿¡æ¯å’Œç»†èŠ‚ï¼š\n\n${content}`;
        break;
      default:
        prompt = `è¯·åˆ†æä»¥ä¸‹å†…å®¹å¹¶æä¾›æœ‰ç”¨çš„è§è§£ï¼š\n\n${content}`;
    }

    const completion = await openai.chat.completions.create({
      messages: [{ role: 'user', content: prompt }],
      model: 'gpt-3.5-turbo',
      max_tokens: 500,
      temperature: 0.7
    });

    return {
      success: true,
      result: completion.choices[0].message.content,
      source: 'OpenAI GPT-3.5',
      type: type
    };

  } catch (error) {
    console.log('OpenAI API é”™è¯¯:', error.message);
    // API å¤±è´¥æ—¶ä½¿ç”¨æ™ºèƒ½å¤‡ç”¨å“åº”
    return generateSmartFallback(content, type);
  }
}

// æ™ºèƒ½å¤‡ç”¨å“åº”å‡½æ•°
function generateSmartFallback(content, type) {
  
  switch (type) {
    case 'summary':
      return {
        success: true,
        result: `ğŸ“ ${content.length > 100 ? content.substring(0, 100) + '...' : content}`,
        source: 'æ™ºèƒ½å¤‡ç”¨ç³»ç»Ÿ',
        type: 'summary'
      };
      
    case 'keywords':
      // ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
      const words = content.split(/[\sï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€]+/)
        .filter(word => word.length > 1)
        .slice(0, 6);
      return {
        success: true,
        result: words.join(', '),
        source: 'æ™ºèƒ½å¤‡ç”¨ç³»ç»Ÿ',
        type: 'keywords'
      };
      
    case 'advice':
      return {
        success: true,
        result: '1. å®šæœŸå¤ä¹ å’Œæ€»ç»“å­¦ä¹ å†…å®¹\n2. ç»“åˆå®é™…æ¡ˆä¾‹åŠ æ·±ç†è§£\n3. ä¸ä»–äººäº¤æµåˆ†äº«å­¦ä¹ å¿ƒå¾—',
        source: 'æ™ºèƒ½å¤‡ç”¨ç³»ç»Ÿ',
        type: 'advice'
      };
      
    case 'expand':
      return {
        success: true,
        result: `${content}\n\nğŸ’¡ å»ºè®®æ·±å…¥äº†è§£ç›¸å…³æ¦‚å¿µï¼Œé€šè¿‡å®è·µåŠ å¼ºç†è§£ï¼Œå¹¶å…³æ³¨æœ€æ–°å‘å±•åŠ¨æ€ã€‚`,
        source: 'æ™ºèƒ½å¤‡ç”¨ç³»ç»Ÿ',
        type: 'expand'
      };
      
    default:
      return {
        success: true,
        result: `å†…å®¹åˆ†æï¼šè¿™æ˜¯ä¸€æ®µå…³äº${content.substring(0, 20)}...çš„å†…å®¹ï¼Œå»ºè®®è¿›ä¸€æ­¥å­¦ä¹ å’Œå®è·µã€‚`,
        source: 'æ™ºèƒ½å¤‡ç”¨ç³»ç»Ÿ',
        type: type
      };
  }
} 